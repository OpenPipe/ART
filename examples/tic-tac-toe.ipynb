{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenPipe client initialized\n"
     ]
    }
   ],
   "source": [
    "import art\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "from openpipe.client import OpenPipe\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "op_client = OpenPipe()\n",
    "print(\"OpenPipe client initialized\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "api = art.LocalAPI(wandb_project=\"agent-reinforcement-training\")\n",
    "model = await api.get_or_create_model(\n",
    "    name=\"tic-tac-toe-002\", base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.95 --max-num-seqs=2048 --max-num-batched-tokens=16384 --num-scheduler-steps=1 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=80 --tensor-parallel-size=1 --tool-call-parser=hermes --served-model-name=tic-tac-toe-002 --port=8000 --api-key=default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.10it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.08s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.13s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.13it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.05it/s]\n",
      "\n",
      "INFO:     Started server process [56289]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34460 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM server started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marctic_fly\u001b[0m (\u001b[33mbased-op\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sky_workdir/examples/wandb/run-20250328_021851-tic-tac-toe-002</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/based-op/agent-reinforcement-training/runs/tic-tac-toe-002' target=\"_blank\">tic-tac-toe-002</a></strong> to <a href='https://wandb.ai/based-op/agent-reinforcement-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/based-op/agent-reinforcement-training' target=\"_blank\">https://wandb.ai/based-op/agent-reinforcement-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/based-op/agent-reinforcement-training/runs/tic-tac-toe-002' target=\"_blank\">https://wandb.ai/based-op/agent-reinforcement-training/runs/tic-tac-toe-002</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"train/completion_tokens\" not found in run history\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96919154cb64245892f427b6ca38559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a012f9adb3c487e844af52cc494df39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 210\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m model.get_iteration(), \u001b[32m10\u001b[39m):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m model.openai_client(\n\u001b[32m    208\u001b[39m         estimated_completion_tokens=\u001b[32m350\u001b[39m, verbosity=\u001b[32m2\u001b[39m\n\u001b[32m    209\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m openai_client:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         val_groups, train_groups = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    211\u001b[39m             art.gather_trajectories(\n\u001b[32m    212\u001b[39m                 (\n\u001b[32m    213\u001b[39m                     (rollout(openai_client, i, is_validation=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m))\n\u001b[32m    214\u001b[39m                 ),\n\u001b[32m    215\u001b[39m                 pbar_desc=\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m                 stream_chat_completions=\u001b[32m8\u001b[39m,\n\u001b[32m    217\u001b[39m                 return_exceptions=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    218\u001b[39m             ),\n\u001b[32m    219\u001b[39m             art.gather_trajectories(\n\u001b[32m    220\u001b[39m                 (\n\u001b[32m    221\u001b[39m                     (rollout(openai_client, i, is_validation=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m50\u001b[39m))\n\u001b[32m    222\u001b[39m                 ),\n\u001b[32m    223\u001b[39m                 pbar_desc=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m                 return_exceptions=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    225\u001b[39m             ),\n\u001b[32m    226\u001b[39m         )\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m model.log(val_groups)\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m model.clear_iterations()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/gather_trajectories.py:85\u001b[39m, in \u001b[36mgather_trajectories\u001b[39m\u001b[34m(groups, pbar_desc, pbar_total_completion_tokens, return_exceptions, stream_chat_completions, streaming_chat_completions_dir, clear_streaming_chat_completions_dir)\u001b[39m\n\u001b[32m     78\u001b[39m context = GroupsContext(\n\u001b[32m     79\u001b[39m     pbar=tqdm.tqdm(desc=pbar_desc, total=total),\n\u001b[32m     80\u001b[39m     pbar_total_completion_tokens=pbar_total_completion_tokens,\n\u001b[32m     81\u001b[39m     should_stream=\u001b[38;5;28miter\u001b[39m(cycle(should_stream)),\n\u001b[32m     82\u001b[39m     streaming_chat_completions_dir=streaming_chat_completions_dir,\n\u001b[32m     83\u001b[39m )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_groups_context(context):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     result_groups = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m     86\u001b[39m         *[\n\u001b[32m     87\u001b[39m             asyncio.gather(\n\u001b[32m     88\u001b[39m                 *[wrap_coroutine(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m g], return_exceptions=return_exceptions\n\u001b[32m     89\u001b[39m             )\n\u001b[32m     90\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m groups\n\u001b[32m     91\u001b[39m         ]\n\u001b[32m     92\u001b[39m     )\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     94\u001b[39m     context.pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/gather_trajectories.py:133\u001b[39m, in \u001b[36mwrap_coroutine\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    131\u001b[39m context.metric_sums[\u001b[33m\"\u001b[39m\u001b[33mexceptions\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m    132\u001b[39m context.update_pbar(n=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/gather_trajectories.py:110\u001b[39m, in \u001b[36mwrap_coroutine\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    108\u001b[39m context = get_groups_context()\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m    111\u001b[39m     context.update_pbar(n=\u001b[32m1\u001b[39m)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Trajectory):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 180\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(client, iteration, is_validation)\u001b[39m\n\u001b[32m    177\u001b[39m trajectory.messages_and_choices.append(choice)\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[43mapply_agent_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    182\u001b[39m     trajectory.reward = \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mapply_agent_move\u001b[39m\u001b[34m(game, move)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnable to parse square\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# check if the move is valid\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgame\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboard\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow_index\u001b[49m\u001b[43m]\u001b[49m[col_index] != \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSquare already occupied\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m game[\u001b[33m\"\u001b[39m\u001b[33mboard\u001b[39m\u001b[33m\"\u001b[39m][row_index][col_index] = game[\u001b[33m\"\u001b[39m\u001b[33magent_symbol\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n",
      "caught exception generating chat completion\n",
      "Connection error.\n"
     ]
    }
   ],
   "source": [
    "import art\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "from typing import TypedDict\n",
    "from openpipe.client import OpenPipe\n",
    "import time\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class TicTacToeGame(TypedDict):\n",
    "    board: list[list[str]]\n",
    "    agent_symbol: Literal[\"x\", \"o\"]\n",
    "    opponent_symbol: Literal[\"x\", \"o\"]\n",
    "\n",
    "def generate_game(board_length: int = 3) -> TicTacToeGame:\n",
    "    board = [[\"_\" for _ in range(board_length)] for _ in range(board_length)]\n",
    "    agent_symbol = random.choice([\"x\", \"o\"])\n",
    "    opponent_symbol = \"x\" if agent_symbol == \"o\" else \"o\"\n",
    "    return {\"board\": board, \"agent_symbol\": agent_symbol, \"opponent_symbol\": opponent_symbol}\n",
    "\n",
    "def render_board(game: TicTacToeGame) -> str:\n",
    "    board = game[\"board\"]\n",
    "    board_length = len(board)\n",
    "    # print something like this:\n",
    "    #    1   2   3\n",
    "    # A  _ | x | x\n",
    "    # B  o | _ | _\n",
    "    # C  _ | o | _\n",
    "    # where _ is an empty cell\n",
    "\n",
    "    board_str = \"   \" + \"   \".join([str(i+1) for i in range(board_length)]) + \"\\n\"\n",
    "    for i in range(board_length):\n",
    "        board_str += f\"{chr(65 + i)}  {board[i][0]} | {board[i][1]} | {board[i][2]}\\n\"\n",
    "    return board_str\n",
    "\n",
    "def get_opponent_move(game: TicTacToeGame) -> tuple[int, int]:\n",
    "    # get a random empty cell\n",
    "    empty_cells = [(i, j) for i in range(3) for j in range(3) if game[\"board\"][i][j] == \"_\"]\n",
    "    return random.choice(empty_cells)\n",
    "\n",
    "class AgentMove(BaseModel):\n",
    "    reason: str\n",
    "    square: str\n",
    "\n",
    "def apply_agent_move(game: TicTacToeGame, move: str) -> None:\n",
    "    board_length = len(game[\"board\"])\n",
    "    json_move = json.loads(move)\n",
    "    square = json_move[\"square\"]\n",
    "\n",
    "    try:\n",
    "        row_index = ord(square[0]) - 65\n",
    "        col_index = int(square[1]) - 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise ValueError(\"Unable to parse square\")\n",
    "\n",
    "    if row_index < 0 or row_index >= board_length or col_index < 0 or col_index >= board_length:\n",
    "        raise ValueError(f\"Invalid move, row or column out of bounds: {row_index}, {col_index}\")\n",
    "\n",
    "    # check if the move is valid\n",
    "    if game[\"board\"][row_index][col_index] != \"_\":\n",
    "        raise ValueError(\"Square already occupied\")\n",
    "\n",
    "    game[\"board\"][row_index][col_index] = game[\"agent_symbol\"]\n",
    "\n",
    "\n",
    "def check_winner(board: list[list[str]]) -> Literal[\"x\", \"o\", \"draw\", None]:\n",
    "    board_length = len(board)\n",
    "    # check rows\n",
    "    for row in board:\n",
    "        if row.count(row[0]) == board_length and row[0] != \"_\":\n",
    "            return row[0]\n",
    "    # check columns\n",
    "    for col in range(board_length):\n",
    "        if [board[row][col] for row in range(board_length)].count(board[0][col]) == board_length and board[0][col] != \"_\":\n",
    "            return board[0][col]\n",
    "\n",
    "    # top right to bottom left\n",
    "    upward_diagonal = [board[i][board_length - i - 1] for i in range(board_length)]\n",
    "    if upward_diagonal.count(upward_diagonal[0]) == board_length and upward_diagonal[0] != \"_\":\n",
    "        return upward_diagonal[0]\n",
    "\n",
    "    # top left to bottom right\n",
    "    downward_diagonal = [board[i][i] for i in range(board_length)]\n",
    "    if downward_diagonal.count(downward_diagonal[0]) == board_length and downward_diagonal[0] != \"_\":\n",
    "        return downward_diagonal[0]\n",
    "\n",
    "    # check for draw\n",
    "    if all(cell != \"_\" for row in board for cell in row):\n",
    "        return \"draw\"\n",
    "    return None\n",
    "\n",
    "def get_trajectory_messages(trajectory: art.Trajectory) -> art.Messages:\n",
    "    messages: art.Messages = []\n",
    "    for item in trajectory.messages_and_choices:\n",
    "\n",
    "        # if item is not a dict, convert it to a dict\n",
    "        if not isinstance(item, dict):\n",
    "            item = item.to_dict()\n",
    "\n",
    "        # check if item is a choice\n",
    "        if \"message\" in item:\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": item[\"message\"][\"content\"]\n",
    "            })\n",
    "        else:\n",
    "            # otherwise it's a message\n",
    "            messages.append(item)\n",
    "    return messages\n",
    "\n",
    "failing_trajectory = None\n",
    "\n",
    "async def rollout(\n",
    "    client: openai.AsyncOpenAI, iteration: int, is_validation: bool\n",
    ") -> art.Trajectory:\n",
    "\n",
    "    game = generate_game()\n",
    "\n",
    "    trajectory = art.Trajectory(\n",
    "        messages_and_choices=[{\"role\": \"system\", \"content\": f\"You are a tic-tac-toe player. You are playing against an opponent. Always choose the move most likely to lead to an eventual win. Return the move in the format 'A1', 'B2', 'C3', etc. You are the {game['agent_symbol']} symbol.\"}], reward=0, metrics={\"test\": 5}\n",
    "    )\n",
    "\n",
    "    if (game[\"agent_symbol\"] == \"o\"):\n",
    "        starting_opponent_move = get_opponent_move(game)\n",
    "        game[\"board\"][starting_opponent_move[0]][starting_opponent_move[1]] = game[\"opponent_symbol\"]\n",
    "\n",
    "\n",
    "    while check_winner(game[\"board\"]) is None:\n",
    "\n",
    "        trajectory.messages_and_choices.append({\"role\": \"user\", \"content\": render_board(game)})\n",
    "\n",
    "        requested_at = int(time.time() * 1000)\n",
    "        messages = get_trajectory_messages(trajectory)\n",
    "\n",
    "        async def get_completion():\n",
    "            return await client.beta.chat.completions.parse(\n",
    "                messages=messages,\n",
    "                model=model.name,\n",
    "                response_format=AgentMove,\n",
    "            )\n",
    "\n",
    "        try: \n",
    "            chat_completion = await get_completion()\n",
    "        except openai.LengthFinishReasonError as e:\n",
    "            print(e)\n",
    "            chat_completion = await get_completion()\n",
    "        except Exception as e:\n",
    "            print(\"caught exception generating chat completion\")\n",
    "            print(e)\n",
    "            global failing_trajectory\n",
    "            failing_trajectory = trajectory\n",
    "            raise e\n",
    "        \n",
    "        op_client.report(\n",
    "            requested_at=requested_at,\n",
    "            received_at=int(time.time() * 1000),\n",
    "            req_payload={\n",
    "                \"model\": model.name,\n",
    "                \"messages\": messages,\n",
    "                \"metadata\": {\n",
    "                    \"notebook-id\": \"tic-tac-toe\",\n",
    "                    \"iteration\": str(iteration),\n",
    "                    \"validation\": str(is_validation),\n",
    "                    \"move_number\": str(len(trajectory.messages_and_choices) - 1),\n",
    "                },\n",
    "            },\n",
    "            resp_payload=chat_completion,\n",
    "            status_code=200,\n",
    "        )\n",
    "\n",
    "        choice = chat_completion.choices[0]\n",
    "        content = choice.message.content\n",
    "        assert isinstance(content, str)\n",
    "        trajectory.messages_and_choices.append(choice)\n",
    "\n",
    "        try:\n",
    "            apply_agent_move(game, content)\n",
    "        except ValueError as e:\n",
    "            trajectory.reward = 0\n",
    "            break\n",
    "\n",
    " \n",
    "\n",
    "        if check_winner(game[\"board\"]) is not None:\n",
    "            break\n",
    "\n",
    "        opponent_move = get_opponent_move(game)\n",
    "        game[\"board\"][opponent_move[0]][opponent_move[1]] = game[\"opponent_symbol\"]\n",
    "\n",
    "    winner = check_winner(game[\"board\"])\n",
    "\n",
    "    if winner == game[\"agent_symbol\"]:\n",
    "        trajectory.reward = 1\n",
    "    elif winner == game[\"opponent_symbol\"]:\n",
    "        trajectory.reward = 0\n",
    "    elif winner == \"draw\":\n",
    "        trajectory.reward = 0.5\n",
    "        \n",
    "    return trajectory\n",
    "\n",
    "\n",
    "stride = 32\n",
    "for i in range(await model.get_iteration(), 10):\n",
    "    async with model.openai_client(\n",
    "        estimated_completion_tokens=350, verbosity=2\n",
    "    ) as openai_client:\n",
    "        val_groups, train_groups = await asyncio.gather(\n",
    "            art.gather_trajectories(\n",
    "                (\n",
    "                    (rollout(openai_client, i, is_validation=True) for _ in range(2))\n",
    "                ),\n",
    "                pbar_desc=\"val\",\n",
    "                stream_chat_completions=8,\n",
    "                return_exceptions=False,\n",
    "            ),\n",
    "            art.gather_trajectories(\n",
    "                (\n",
    "                    (rollout(openai_client, i, is_validation=False) for _ in range(50))\n",
    "                ),\n",
    "                pbar_desc=\"train\",\n",
    "                return_exceptions=False,\n",
    "            ),\n",
    "        )\n",
    "    await model.log(val_groups)\n",
    "    await model.clear_iterations()\n",
    "    await model.tune(\n",
    "        train_groups, config=art.TuneConfig(plot_tensors=True, verbosity=2)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
