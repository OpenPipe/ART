{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".cell-output-ipywidget-background {\n",
              "    background-color: transparent !important;\n",
              "}\n",
              ":root {\n",
              "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
              "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
              "}  \n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%html\n",
        "<style>\n",
        ".cell-output-ipywidget-background {\n",
        "    background-color: transparent !important;\n",
        "}\n",
        ":root {\n",
        "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
        "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
        "}  \n",
        "</style>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenPipe client initialized\n"
          ]
        }
      ],
      "source": [
        "import art\n",
        "from dotenv import load_dotenv\n",
        "import random\n",
        "from openpipe.client import OpenPipe\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "op_client = OpenPipe()\n",
        "print(\"OpenPipe client initialized\")\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "api = art.UnslothAPI(wandb_project=\"agent-reinforcement-training\")\n",
        "model = await api.get_or_create_model(\n",
        "    name=\"tic-tac-toe-003\", base_model=\"Qwen/Qwen2.5-7B-Instruct\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Patching Xformers to fix some performance issues.\n",
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:496: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  left = re.match(\"[\\s\\n]{4,}\", leftover).span()[1]\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:924: SyntaxWarning: invalid escape sequence '\\*'\n",
            "  .replace(\"*\", \"\\*\").replace(\"^\", \"\\^\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:924: SyntaxWarning: invalid escape sequence '\\^'\n",
            "  .replace(\"*\", \"\\*\").replace(\"^\", \"\\^\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:925: SyntaxWarning: invalid escape sequence '\\-'\n",
            "  .replace(\"-\", \"\\-\").replace(\"_\", \"\\_\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:925: SyntaxWarning: invalid escape sequence '\\_'\n",
            "  .replace(\"-\", \"\\-\").replace(\"_\", \"\\_\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:926: SyntaxWarning: invalid escape sequence '\\:'\n",
            "  .replace(\":\", \"\\:\").replace(\"+\", \"\\+\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:926: SyntaxWarning: invalid escape sequence '\\+'\n",
            "  .replace(\":\", \"\\:\").replace(\"+\", \"\\+\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:927: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  .replace(\".\", \"\\.\").replace(\",\", \"\\,\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:927: SyntaxWarning: invalid escape sequence '\\,'\n",
            "  .replace(\".\", \"\\.\").replace(\",\", \"\\,\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:928: SyntaxWarning: invalid escape sequence '\\('\n",
            "  .replace(\"(\", \"\\(\").replace(\")\", \"\\)\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:928: SyntaxWarning: invalid escape sequence '\\)'\n",
            "  .replace(\"(\", \"\\(\").replace(\")\", \"\\)\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:929: SyntaxWarning: invalid escape sequence '\\['\n",
            "  .replace(\"[\", \"\\[\").replace(\"]\", \"\\]\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:929: SyntaxWarning: invalid escape sequence '\\]'\n",
            "  .replace(\"[\", \"\\[\").replace(\"]\", \"\\]\")\\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1018: SyntaxWarning: invalid escape sequence '\\_'\n",
            "  if \"loss\\_function\" in cross_entropy_find and \"loss_function\" not in forward:\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1020: SyntaxWarning: invalid escape sequence '\\_'\n",
            "  elif \"loss\\_function\" not in cross_entropy_find and \"loss_function\" in forward:\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1056: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  if \"logits = outputs\\.logits\" in cross_entropy_find:\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1163: SyntaxWarning: invalid escape sequence '\\:'\n",
            "  r\"for ([^\\s]{1,}) in \" + modulelist_item + \"\\:[\\n]\" + \\\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1406: SyntaxWarning: invalid escape sequence '\\('\n",
            "  regex_find = f\"{call_class}\\(([^\\)]{{1,}})\\)\"\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1406: SyntaxWarning: invalid escape sequence '\\)'\n",
            "  regex_find = f\"{call_class}\\(([^\\)]{{1,}})\\)\"\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1412: SyntaxWarning: invalid escape sequence '\\('\n",
            "  regex_find = \"def forward\\(([^\\)]{1,})\\)\"\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1518: SyntaxWarning: invalid escape sequence '\\)'\n",
            "  inherited_modules = re.findall(r\"class ([^\\s]{1,})\\(\" + inherited_class + \"\\)\", full_source)\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/compiler.py:1572: SyntaxWarning: invalid escape sequence '\\('\n",
            "  called = re.findall(r\"[\\s]{1,}\" + re.escape(function) + \"\\(.+?\\)\", full_source, flags = re.DOTALL)\n",
            "/root/sky_workdir/.venv/lib/python3.12/site-packages/unsloth_zoo/peft_utils.py:223: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  name = re.sub(\"\\.([\\d]{1,})\\.\", r\"[\\1].\", name)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 04-04 17:42:42 __init__.py:207] Automatically detected platform cuda.\n",
            "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.49.0. vLLM: 0.7.3.\n",
            "   \\\\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.097 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit with actual GPU utilization = 32.2%\n",
            "Unsloth: Your GPU has CUDA compute capability 9.0 with VRAM = 79.1 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 32768. Num Sequences = 288.\n",
            "Unsloth: vLLM's KV Cache can use up to 19.6 GB. Also swap space = 6 GB.\n",
            "INFO 04-04 17:42:57 config.py:549] This model supports multiple tasks: {'reward', 'score', 'embed', 'classify', 'generate'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.0.self_attn', 'model.layers.1.self_attn', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.4.mlp', 'model.layers.25.mlp', 'model.layers.26.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 04-04 17:42:57 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":288}, use_cached_outputs=False, \n",
            "INFO 04-04 17:43:00 cuda.py:229] Using Flash Attention backend.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W404 17:43:00.441493345 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 04-04 17:43:00 model_runner.py:1110] Starting to load model unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit...\n",
            "INFO 04-04 17:43:00 loader.py:1089] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 04-04 17:43:00 weight_utils.py:254] Using model weights format ['*.safetensors']\n",
            "INFO 04-04 17:43:37 weight_utils.py:270] Time spent downloading weights for unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit: 36.770054 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.47s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.10it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.52s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.03s/it]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 04-04 17:43:42 model_runner.py:1115] Loading model weights took 6.7252 GB\n",
            "INFO 04-04 17:43:42 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 04-04 17:43:49 worker.py:267] Memory profiling takes 7.55 seconds\n",
            "INFO 04-04 17:43:49 worker.py:267] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.32) = 25.47GiB\n",
            "INFO 04-04 17:43:49 worker.py:267] model weights take 6.73GiB; non_torch_memory takes 0.14GiB; PyTorch activation peak memory takes 4.72GiB; the rest of the memory reserved for KV Cache is 13.88GiB.\n",
            "INFO 04-04 17:43:50 executor_base.py:111] # cuda blocks: 16246, # CPU blocks: 7021\n",
            "INFO 04-04 17:43:50 executor_base.py:116] Maximum concurrency for 32768 tokens per request: 7.93x\n",
            "INFO 04-04 17:43:56 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:32<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 04-04 17:44:28 model_runner.py:1562] Graph capturing finished in 33 secs, took 0.89 GiB\n",
            "INFO 04-04 17:44:28 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 46.81 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edc29ee24404424a9539ce6861765553",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "CancelledError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 271\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m model.get_iteration(), \u001b[32m500\u001b[39m):\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m model.openai_client(\n\u001b[32m    269\u001b[39m         estimated_completion_tokens=\u001b[32m100\u001b[39m, verbosity=\u001b[32m2\u001b[39m\n\u001b[32m    270\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m openai_client:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         train_groups = \u001b[38;5;28;01mawait\u001b[39;00m art.gather_trajectories(\n\u001b[32m    272\u001b[39m                 (\n\u001b[32m    273\u001b[39m                     (rollout(openai_client, i, is_validation=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m512\u001b[39m))\n\u001b[32m    274\u001b[39m                     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m)\n\u001b[32m    275\u001b[39m                 ),\n\u001b[32m    276\u001b[39m                 pbar_desc=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    277\u001b[39m                 return_exceptions=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    278\u001b[39m             )\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m model.clear_iterations()\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m model.tune(\n\u001b[32m    281\u001b[39m         train_groups, config=art.TuneConfig(plot_tensors=\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity=\u001b[32m2\u001b[39m, lr=\u001b[32m1e-4\u001b[39m, kl_coef=\u001b[32m0.04\u001b[39m, sequence_length=\u001b[32m32768\u001b[39m)\n\u001b[32m    282\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/gather_trajectories.py:85\u001b[39m, in \u001b[36mgather_trajectories\u001b[39m\u001b[34m(groups, pbar_desc, pbar_total_completion_tokens, return_exceptions, stream_chat_completions, streaming_chat_completions_dir, clear_streaming_chat_completions_dir)\u001b[39m\n\u001b[32m     78\u001b[39m context = GroupsContext(\n\u001b[32m     79\u001b[39m     pbar=tqdm.tqdm(desc=pbar_desc, total=total),\n\u001b[32m     80\u001b[39m     pbar_total_completion_tokens=pbar_total_completion_tokens,\n\u001b[32m     81\u001b[39m     should_stream=\u001b[38;5;28miter\u001b[39m(cycle(should_stream)),\n\u001b[32m     82\u001b[39m     streaming_chat_completions_dir=streaming_chat_completions_dir,\n\u001b[32m     83\u001b[39m )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_groups_context(context):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     result_groups = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m     86\u001b[39m         *[\n\u001b[32m     87\u001b[39m             asyncio.gather(\n\u001b[32m     88\u001b[39m                 *[wrap_coroutine(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m g], return_exceptions=return_exceptions\n\u001b[32m     89\u001b[39m             )\n\u001b[32m     90\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m groups\n\u001b[32m     91\u001b[39m         ]\n\u001b[32m     92\u001b[39m     )\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     94\u001b[39m     context.pbar.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/gather_trajectories.py:133\u001b[39m, in \u001b[36mwrap_coroutine\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    131\u001b[39m context.metric_sums[\u001b[33m\"\u001b[39m\u001b[33mexceptions\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m    132\u001b[39m context.update_pbar(n=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/gather_trajectories.py:110\u001b[39m, in \u001b[36mwrap_coroutine\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    108\u001b[39m context = get_groups_context()\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m    111\u001b[39m     context.update_pbar(n=\u001b[32m1\u001b[39m)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Trajectory):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/utils.py:95\u001b[39m, in \u001b[36mretry.<locals>.decorator.<locals>.async_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, max_attempts + \u001b[32m1\u001b[39m):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(*args, **kwargs)\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m         last_exception = e\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(client, iteration, is_validation)\u001b[39m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(\n\u001b[32m    184\u001b[39m         max_completion_tokens=\u001b[32m2048\u001b[39m,\n\u001b[32m    185\u001b[39m         messages=messages,\n\u001b[32m    186\u001b[39m         model=model.name,\n\u001b[32m    187\u001b[39m         extra_body={\u001b[33m\"\u001b[39m\u001b[33mguided_json\u001b[39m\u001b[33m\"\u001b[39m: AgentMove.model_json_schema()},\n\u001b[32m    188\u001b[39m     )\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     chat_completion = \u001b[38;5;28;01mawait\u001b[39;00m get_completion()\n\u001b[32m    192\u001b[39m     last_completion = chat_completion\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.LengthFinishReasonError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 183\u001b[39m, in \u001b[36mrollout.<locals>.get_completion\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_completion\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(\n\u001b[32m    184\u001b[39m         max_completion_tokens=\u001b[32m2048\u001b[39m,\n\u001b[32m    185\u001b[39m         messages=messages,\n\u001b[32m    186\u001b[39m         model=model.name,\n\u001b[32m    187\u001b[39m         extra_body={\u001b[33m\"\u001b[39m\u001b[33mguided_json\u001b[39m\u001b[33m\"\u001b[39m: AgentMove.model_json_schema()},\n\u001b[32m    188\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/openai.py:48\u001b[39m, in \u001b[36mpatch_openai.<locals>.create_patched\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     47\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m     49\u001b[39m     return_value = \u001b[38;5;28;01mawait\u001b[39;00m create(*args, **kwargs)\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_value, ChatCompletion):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/locks.py:14\u001b[39m, in \u001b[36m_ContextManagerMixin.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.acquire()\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# We have no use for the \"as ...\"  clause in the with\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# statement for locks.\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/locks.py:386\u001b[39m, in \u001b[36mSemaphore.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m._waiters.remove(fut)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/futures.py:289\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    288\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/futures.py:197\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the result this future represents.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m    192\u001b[39m \u001b[33;03mIf the future has been cancelled, raises CancelledError.  If the\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[33;03mfuture's result isn't yet available, raises InvalidStateError.  If\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[33;03mthe future is done and has an exception set, this exception is raised.\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mCancelledError\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import art\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "import openai\n",
        "import random\n",
        "from typing import TypedDict\n",
        "from openpipe.client import OpenPipe\n",
        "import time\n",
        "from typing import Literal\n",
        "from pydantic import BaseModel\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "class TicTacToeGame(TypedDict):\n",
        "    board: list[list[str]]\n",
        "    agent_symbol: Literal[\"x\", \"o\"]\n",
        "    opponent_symbol: Literal[\"x\", \"o\"]\n",
        "\n",
        "\n",
        "def generate_game(board_length: int = 3) -> TicTacToeGame:\n",
        "    board = [[\"_\" for _ in range(board_length)] for _ in range(board_length)]\n",
        "    agent_symbol = random.choice([\"x\", \"o\"])\n",
        "    opponent_symbol = \"x\" if agent_symbol == \"o\" else \"o\"\n",
        "    return {\n",
        "        \"board\": board,\n",
        "        \"agent_symbol\": agent_symbol,\n",
        "        \"opponent_symbol\": opponent_symbol,\n",
        "    }\n",
        "\n",
        "\n",
        "def render_board(game: TicTacToeGame) -> str:\n",
        "    board = game[\"board\"]\n",
        "    board_length = len(board)\n",
        "    # print something like this:\n",
        "    #    1   2   3\n",
        "    # A  _ | x | x\n",
        "    # B  o | _ | _\n",
        "    # C  _ | o | _\n",
        "    # where _ is an empty cell\n",
        "\n",
        "    board_str = \"   \" + \"   \".join([str(i + 1) for i in range(board_length)]) + \"\\n\"\n",
        "    for i in range(board_length):\n",
        "        board_str += f\"{chr(65 + i)}  {board[i][0]} | {board[i][1]} | {board[i][2]}\\n\"\n",
        "    return board_str\n",
        "\n",
        "\n",
        "def get_opponent_move(game: TicTacToeGame) -> tuple[int, int]:\n",
        "    # get a random empty cell\n",
        "    empty_cells = [\n",
        "        (i, j) for i in range(3) for j in range(3) if game[\"board\"][i][j] == \"_\"\n",
        "    ]\n",
        "    return random.choice(empty_cells)\n",
        "\n",
        "\n",
        "class AgentMove(BaseModel):\n",
        "    reason: str\n",
        "    square: str\n",
        "\n",
        "\n",
        "def apply_agent_move(game: TicTacToeGame, move: str) -> None:\n",
        "    board_length = len(game[\"board\"])\n",
        "    json_move = json.loads(move)\n",
        "    square = json_move[\"square\"]\n",
        "\n",
        "    try:\n",
        "        row_index = ord(square[0]) - 65\n",
        "        col_index = int(square[1]) - 1\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        raise ValueError(\"Unable to parse square\")\n",
        "\n",
        "    if (\n",
        "        row_index < 0\n",
        "        or row_index >= board_length\n",
        "        or col_index < 0\n",
        "        or col_index >= board_length\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Invalid move, row or column out of bounds: {row_index}, {col_index}\"\n",
        "        )\n",
        "\n",
        "    # check if the move is valid\n",
        "    if game[\"board\"][row_index][col_index] != \"_\":\n",
        "        raise ValueError(\"Square already occupied\")\n",
        "\n",
        "    game[\"board\"][row_index][col_index] = game[\"agent_symbol\"]\n",
        "\n",
        "\n",
        "def check_winner(board: list[list[str]]) -> Literal[\"x\", \"o\", \"draw\", None]:\n",
        "    board_length = len(board)\n",
        "    # check rows\n",
        "    for row in board:\n",
        "        if row.count(row[0]) == board_length and row[0] != \"_\":\n",
        "            return row[0]\n",
        "    # check columns\n",
        "    for col in range(board_length):\n",
        "        if [board[row][col] for row in range(board_length)].count(\n",
        "            board[0][col]\n",
        "        ) == board_length and board[0][col] != \"_\":\n",
        "            return board[0][col]\n",
        "\n",
        "    # top right to bottom left\n",
        "    upward_diagonal = [board[i][board_length - i - 1] for i in range(board_length)]\n",
        "    if (\n",
        "        upward_diagonal.count(upward_diagonal[0]) == board_length\n",
        "        and upward_diagonal[0] != \"_\"\n",
        "    ):\n",
        "        return upward_diagonal[0]\n",
        "\n",
        "    # top left to bottom right\n",
        "    downward_diagonal = [board[i][i] for i in range(board_length)]\n",
        "    if (\n",
        "        downward_diagonal.count(downward_diagonal[0]) == board_length\n",
        "        and downward_diagonal[0] != \"_\"\n",
        "    ):\n",
        "        return downward_diagonal[0]\n",
        "\n",
        "    # check for draw\n",
        "    if all(cell != \"_\" for row in board for cell in row):\n",
        "        return \"draw\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_trajectory_messages(trajectory: art.Trajectory) -> art.Messages:\n",
        "    messages: art.Messages = []\n",
        "    for item in trajectory.messages_and_choices:\n",
        "\n",
        "        # if item is not a dict, convert it to a dict\n",
        "        if not isinstance(item, dict):\n",
        "            item = item.to_dict()\n",
        "\n",
        "        # check if item is a choice\n",
        "        if \"message\" in item:\n",
        "            messages.append(\n",
        "                {\"role\": \"assistant\", \"content\": item[\"message\"][\"content\"]}\n",
        "            )\n",
        "        else:\n",
        "            # otherwise it's a message\n",
        "            messages.append(item)\n",
        "    return messages\n",
        "\n",
        "\n",
        "failing_trajectory = None\n",
        "\n",
        "\n",
        "@art.retry(exceptions=(openai.LengthFinishReasonError,))\n",
        "async def rollout(\n",
        "    client: openai.AsyncOpenAI, iteration: int, is_validation: bool\n",
        ") -> art.Trajectory:\n",
        "\n",
        "    game = generate_game()\n",
        "\n",
        "    trajectory = art.Trajectory(\n",
        "        messages_and_choices=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a tic-tac-toe player. You are playing against an opponent. Always choose the move most likely to lead to an eventual win. Return the move in the format 'A1', 'B2', 'C3', etc. You are the {game['agent_symbol']} symbol.\",\n",
        "            }\n",
        "        ],\n",
        "        reward=0,\n",
        "        metrics={\"test\": 5},\n",
        "    )\n",
        "\n",
        "    if game[\"agent_symbol\"] == \"o\":\n",
        "        starting_opponent_move = get_opponent_move(game)\n",
        "        game[\"board\"][starting_opponent_move[0]][starting_opponent_move[1]] = game[\n",
        "            \"opponent_symbol\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    while check_winner(game[\"board\"]) is None:\n",
        "\n",
        "        trajectory.messages_and_choices.append(\n",
        "            {\"role\": \"user\", \"content\": render_board(game)}\n",
        "        )\n",
        "\n",
        "        requested_at = int(time.time() * 1000)\n",
        "        messages = get_trajectory_messages(trajectory)\n",
        "\n",
        "        async def get_completion():\n",
        "            return await client.chat.completions.create(\n",
        "                max_completion_tokens=2048,\n",
        "                messages=messages,\n",
        "                model=model.name,\n",
        "                extra_body={\"guided_json\": AgentMove.model_json_schema()},\n",
        "            )\n",
        "\n",
        "        try:\n",
        "            chat_completion = await get_completion()\n",
        "            last_completion = chat_completion\n",
        "        except openai.LengthFinishReasonError as e:\n",
        "            raise e\n",
        "        except Exception as e:\n",
        "            print(\"caught exception generating chat completion\")\n",
        "            print(e)\n",
        "            global failing_trajectory\n",
        "            failing_trajectory = trajectory\n",
        "            raise e\n",
        "\n",
        "        try:\n",
        "            op_client.report(\n",
        "                requested_at=requested_at,\n",
        "                received_at=int(time.time() * 1000),\n",
        "                req_payload={\n",
        "                    \"model\": model.name,\n",
        "                    \"messages\": messages,\n",
        "                    \"metadata\": {\n",
        "                        \"notebook-id\": \"tic-tac-toe\",\n",
        "                        \"iteration\": str(iteration),\n",
        "                        \"validation\": str(is_validation),\n",
        "                        \"move_number\": str(len(trajectory.messages_and_choices) - 1),\n",
        "                    },\n",
        "                },\n",
        "                resp_payload=chat_completion,\n",
        "                status_code=200,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error reporting to OpenPipe: {e}\")\n",
        "\n",
        "        choice = chat_completion.choices[0]\n",
        "        content = choice.message.content\n",
        "        assert isinstance(content, str)\n",
        "        trajectory.messages_and_choices.append(choice)\n",
        "\n",
        "        try:\n",
        "            apply_agent_move(game, content)\n",
        "        except ValueError as e:\n",
        "            trajectory.reward = -1\n",
        "            break\n",
        "\n",
        "        if check_winner(game[\"board\"]) is not None:\n",
        "            break\n",
        "\n",
        "        opponent_move = get_opponent_move(game)\n",
        "        game[\"board\"][opponent_move[0]][opponent_move[1]] = game[\"opponent_symbol\"]\n",
        "\n",
        "    winner = check_winner(game[\"board\"])\n",
        "\n",
        "    if winner == game[\"agent_symbol\"]:\n",
        "        trajectory.reward = 1\n",
        "    elif winner == game[\"opponent_symbol\"]:\n",
        "        trajectory.reward = 0\n",
        "    elif winner == \"draw\":\n",
        "        trajectory.reward = 0.5\n",
        "\n",
        "    try:\n",
        "        op_client.update_log_metadata(\n",
        "            filters=[\n",
        "                {\n",
        "                    \"field\": \"completionId\",\n",
        "                    \"equals\": last_completion.id,\n",
        "                }\n",
        "            ],\n",
        "            metadata={\n",
        "                \"reward\": str(trajectory.reward),\n",
        "                \"reward_assigned\": \"true\",\n",
        "            }\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating log metadata: {e}\")\n",
        "\n",
        "    return trajectory\n",
        "\n",
        "\n",
        "for i in range(await model.get_iteration(), 1000):\n",
        "    async with model.openai_client(\n",
        "        estimated_completion_tokens=100, verbosity=2\n",
        "    ) as openai_client:\n",
        "        train_groups = await art.gather_trajectories(\n",
        "                (\n",
        "                    (rollout(openai_client, i, is_validation=False) for _ in range(48))\n",
        "                    for _ in range(1)\n",
        "                ),\n",
        "                pbar_desc=\"train\",\n",
        "                return_exceptions=False,\n",
        "            )\n",
        "    await model.clear_iterations()\n",
        "    await model.tune(\n",
        "        train_groups, config=art.TuneConfig(plot_tensors=True, verbosity=2, lr=1e-4, kl_coef=0.04, sequence_length=32768)\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
