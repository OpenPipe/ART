{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!uv pip install openpipe-art openpipe --prerelease allow --no-cache-dir\n",
        "!uv pip install patchright"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%html\n",
        "<style>\n",
        ".cell-output-ipywidget-background {\n",
        "    background-color: transparent !important;\n",
        "}\n",
        ":root {\n",
        "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
        "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
        "}  \n",
        "</style>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import art\n",
        "import random\n",
        "from dotenv import load_dotenv\n",
        "from art.utils.get_repo_root_path import get_repo_root_path\n",
        "from art.skypilot import SkyPilotBackend\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "root_path = get_repo_root_path()\n",
        "\n",
        "backend = await SkyPilotBackend.initialize_cluster(\n",
        "    cluster_name=\"bo-art-wikilinks-single-turn\",\n",
        "    art_version=root_path,\n",
        "    env_path=f\"{root_path}/.env\",\n",
        "    gpu=\"H100-SXM\"\n",
        ")\n",
        "\n",
        "model = art.TrainableModel(\n",
        "    name=\"001-wiki-game\", project=\"wiki-game\", base_model=\"Qwen/Qwen2.5-14B-Instruct\"\n",
        ")\n",
        "\n",
        "await backend._experimental_pull_from_s3(\n",
        "    model,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "await model.register(backend)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from patchright.async_api import async_playwright\n",
        "\n",
        "import art\n",
        "\n",
        "async def get_random_wikipedia_url():\n",
        "    with open(\"pages.txt\") as f:\n",
        "        pages = f.readlines()\n",
        "    page = random.choice(pages).strip()\n",
        "    return f\"https://en.wikipedia.org/wiki/{page}\"\n",
        "\n",
        "async def extract_links(page):\n",
        "    # Extract links in paragraphs before the References section\n",
        "    links = await page.evaluate(\"\"\"\n",
        "         () => {\n",
        "             const content = document.querySelector('#mw-content-text .mw-parser-output');\n",
        "             const links = [];\n",
        "             let stop = false;\n",
        "             for (let node of content.children) {\n",
        "                 // Stop if we reach the references or similar sections\n",
        "                 if (node.tagName === 'H2' && node.innerText.match(/References|Notes|External links|See also/i)) {\n",
        "                     break;\n",
        "                 }\n",
        "                 // Collect links only from <p> and <ul> elements\n",
        "                 if (node.tagName === 'P' || node.tagName === 'UL') {\n",
        "                     for (let a of node.querySelectorAll('a[href^=\"/wiki/\"]:not([href*=\":\"])')) {\n",
        "                         links.push(a.getAttribute('href'));\n",
        "                     }\n",
        "                 }\n",
        "             }\n",
        "             // Remove duplicates and trim '/wiki/'\n",
        "             return [...new Set(links)].map(link => link.replace('/wiki/', ''));\n",
        "         }\n",
        "     \"\"\")\n",
        "    return links\n",
        "\n",
        "\n",
        "@art.retry(exceptions=(openai.LengthFinishReasonError, requests.ReadTimeout))\n",
        "async def rollout(model: art.Model, step: int, start_url, end_url,\n",
        "                  is_validation: bool) -> art.Trajectory:\n",
        "    MAX_HOPS = 20\n",
        "    HEADLESS = True\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "\n",
        "        episode_trajectories = []\n",
        "\n",
        "        browser = await p.chromium.launch(headless=HEADLESS)\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        url = start_url\n",
        "        hop = 0\n",
        "        visited_pages = set()\n",
        "\n",
        "        while hop < MAX_HOPS:\n",
        "            current_trajectory = art.Trajectory(\n",
        "                messages_and_choices=[{\n",
        "                    \"role\":\n",
        "                    \"system\",\n",
        "                    \"content\":\n",
        "                    \"You are playing the wikilinks game. You are given a starting page and a target page. You need to find a shortest path from the starting page to the target page. You can only visit pages that are accesible from the current page. You will be given a list of pages you can navigate from the current page, and you need to choose the next page to visit from that list. Available pages will be presented in the follofing format: <available_pages><o>{page}</o><o>{page}</o><o>{page}</o></available_pages>. Return ONLY the page name without tags choosing ONLY from the list of available pages.\",\n",
        "                }],\n",
        "                reward=0,\n",
        "            )\n",
        "            current_trajectory.metrics[\"reached_targed\"] = 0\n",
        "            current_trajectory.metrics[\"halucinated\"] = 0\n",
        "\n",
        "            episode_trajectories.append(current_trajectory)\n",
        "\n",
        "            try:\n",
        "                await page.goto(url, timeout=1000000)\n",
        "                await page.wait_for_selector(\"#mw-content-text\",\n",
        "                                             timeout=1000000)\n",
        "            except Exception as e:\n",
        "                print(f\"Error navigating to page {url}: {e}\")\n",
        "                break\n",
        "\n",
        "            available_pages = await extract_links(page)\n",
        "            if not available_pages:\n",
        "                print(\"No valid links found. Stopping.\")\n",
        "                break\n",
        "\n",
        "            visited_pages.add(url)\n",
        "\n",
        "            current_trajectory.messages_and_choices.append({\n",
        "                \"role\":\n",
        "                \"user\",\n",
        "                \"content\":\n",
        "                f\"Current page: {url.split('/wiki/')[-1]}\\nTarget page: {end_url.split('/wiki/')[-1]}\\n\\nAvailable links on the current page:\\n\"\n",
        "                + \"\\n\".join(f\"{page}\" for page in available_pages) +\n",
        "                (\"\\nVisited pages: \" +\n",
        "                 \" -> \".join(visited_pages) if visited_pages else \"\") +\n",
        "                \"\\n\\nWhich link should I open next to reach the target page in the fewest steps? Return only the link (page name) choosing ONLY from the list of links available from the current page.\"\n",
        "            })\n",
        "            messages = current_trajectory.messages()\n",
        "\n",
        "            try:\n",
        "                model_client = model.openai_client()\n",
        "                chat_completion = await model_client.chat.completions.create(\n",
        "                    max_completion_tokens=35,\n",
        "                    messages=messages,\n",
        "                    model=model.inference_model_name,\n",
        "                )\n",
        "\n",
        "                choice = chat_completion.choices[0]\n",
        "                next_link = choice.message.content\n",
        "\n",
        "                assert isinstance(next_link, str)\n",
        "                current_trajectory.messages_and_choices.append(choice)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\"caught exception generating chat completion\", e)\n",
        "                raise e\n",
        "\n",
        "            if next_link not in available_pages:\n",
        "                current_trajectory.metrics[\"halucinated\"] = 1\n",
        "                print(f\"Invalid link: {next_link}. Step: {step}. Hop: {hop}\")\n",
        "                break\n",
        "\n",
        "            url = \"https://en.wikipedia.org/wiki/\" + next_link\n",
        "\n",
        "            if url == end_url:\n",
        "                for t in episode_trajectories:\n",
        "                    t.reward = 5 / (hop + 1)\n",
        "                    t.metrics[\"reached_targed\"] = 1\n",
        "                    t.metrics[\"path_to_target\"] = hop + 1\n",
        "\n",
        "                print(f\"Reached target page in {hop} steps\")\n",
        "                break\n",
        "\n",
        "            hop += 1\n",
        "\n",
        "        if hop == MAX_HOPS:\n",
        "            print(f\"Reached max hops: {MAX_HOPS}\")\n",
        "\n",
        "        await browser.close()\n",
        "        return episode_trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(await model.get_step(), 400):\n",
        "\n",
        "    start_url = await get_random_wikipedia_url()\n",
        "    end_url = await get_random_wikipedia_url()\n",
        "\n",
        "    train_rollout_results = await asyncio.gather(\n",
        "        *(rollout(model, i, start_url, end_url, is_validation=False) for _ in range(10))\n",
        "    )\n",
        "    \n",
        "    # Flatten training trajectories\n",
        "    train_trajectories = [\n",
        "        trajectory \n",
        "        for rollout_result in train_rollout_results \n",
        "        for trajectory in rollout_result\n",
        "    ]\n",
        "    \n",
        "    await model.delete_checkpoints()\n",
        "\n",
        "    await model.train(\n",
        "        [art.TrajectoryGroup(train_trajectories)],\n",
        "        config=art.TrainConfig(learning_rate=5e-6)\n",
        "    )\n",
        "\n",
        "    await backend._experimental_push_to_s3(\n",
        "        model,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "DESTROY_AFTER_RUN = False\n",
        "\n",
        "if DESTROY_AFTER_RUN:\n",
        "    await backend.down()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
