{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mVLLM_USE_V1\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_llm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncLLMEngine\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marg_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncEngineArgs\n\u001b[32m      7\u001b[39m engine = AsyncLLMEngine.from_engine_args(\n\u001b[32m      8\u001b[39m     AsyncEngineArgs(\n\u001b[32m      9\u001b[39m         **{\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     )\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marg_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncEngineArgs, EngineArgs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_llm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncLLMEngine\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMEngine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (CacheConfig, CompilationConfig, ConfigFormat,\n\u001b[32m     16\u001b[39m                          DecodingConfig, DeviceConfig, HfOverrides,\n\u001b[32m     17\u001b[39m                          KVTransferConfig, LoadConfig, LoadFormat, LoRAConfig,\n\u001b[32m     18\u001b[39m                          ModelConfig, ModelImpl, ObservabilityConfig,\n\u001b[32m     19\u001b[39m                          ParallelConfig, PoolerConfig, PromptAdapterConfig,\n\u001b[32m     20\u001b[39m                          SchedulerConfig, SpeculativeConfig, TaskOption,\n\u001b[32m     21\u001b[39m                          TokenizerPoolConfig, VllmConfig)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutor_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExecutorBase\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/config.py:29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompilation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minductor_pass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallableInductorPass, InductorPass\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (QUANTIZATION_METHODS,\n\u001b[32m     30\u001b[39m                                                      get_quantization_config)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelRegistry\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CpuArchEnum\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/model_executor/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BasevLLMParameter,\n\u001b[32m      4\u001b[39m                                            PackedvLLMParameter)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msampling_metadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (SamplingMetadata,\n\u001b[32m      6\u001b[39m                                                    SamplingMetadataCache)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_random_seed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/model_executor/parameter.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tensor_model_parallel_rank\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _make_synced_weight_loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/distributed/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommunication_op\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/distributed/communication_op.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_tp_group\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtensor_model_parallel_all_reduce\u001b[39m(input_: torch.Tensor) -> torch.Tensor:\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"All-reduce the input tensor across model parallel group.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/distributed/parallel_state.py:40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Backend, ProcessGroup\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_transfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_transfer_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkv_transfer\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevice_communicators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_device_communicator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     43\u001b[39m     DeviceCommunicatorBase)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/distributed/kv_transfer/kv_transfer_agent.py:16\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VllmConfig\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_transfer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkv_connector\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfactory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     KVConnectorFactory)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntermediateTensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/distributed/kv_transfer/kv_connector/factory.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Callable, Dict, Type\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KVConnectorBase\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VllmConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/distributed/kv_transfer/kv_connector/base.py:15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, List, Tuple, Union\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntermediateTensors\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VllmConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/sequence.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmsgspec\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SingletonInputs, SingletonInputsAdapter\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlora\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoRARequest\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmultimodal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiModalDataDict, MultiModalPlaceholderDict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/inputs/__init__.py:9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (DecoderOnlyInputs, EncoderDecoderInputs,\n\u001b[32m      4\u001b[39m                    ExplicitEncoderDecoderPrompt, ProcessorInputs, PromptType,\n\u001b[32m      5\u001b[39m                    SingletonInputs, SingletonInputsAdapter, SingletonPrompt,\n\u001b[32m      6\u001b[39m                    TextPrompt, TokenInputs, TokensPrompt,\n\u001b[32m      7\u001b[39m                    build_explicit_enc_dec_prompt, to_enc_dec_tuple_list,\n\u001b[32m      8\u001b[39m                    token_inputs, zip_enc_dec_prompts)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (DummyData, InputContext, InputProcessingContext,\n\u001b[32m     10\u001b[39m                        InputRegistry)\n\u001b[32m     12\u001b[39m INPUT_REGISTRY = InputRegistry()\n\u001b[32m     13\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03mThe global :class:`~InputRegistry` which is used by :class:`~vllm.LLMEngine`\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03mto dispatch data processing according to the target model.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/inputs/registry.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (TYPE_CHECKING, Any, Callable, NamedTuple, Optional,\n\u001b[32m      8\u001b[39m                     Protocol, Union)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature, PretrainedConfig, ProcessorMixin\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypeVar, assert_never\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1851\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1849\u001b[39m     value = Placeholder\n\u001b[32m   1850\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._class_to_module.keys():\n\u001b[32m-> \u001b[39m\u001b[32m1851\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1852\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   1853\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1863\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   1861\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1863\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1864\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1865\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1866\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m because of the following error (look up to see its\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1867\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1868\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     34\u001b[39m     ChannelDimension,\n\u001b[32m     35\u001b[39m     ImageInput,\n\u001b[32m     36\u001b[39m     VideoInput,\n\u001b[32m     37\u001b[39m     is_valid_image,\n\u001b[32m     38\u001b[39m     is_vision_available,\n\u001b[32m     39\u001b[39m     load_image,\n\u001b[32m     40\u001b[39m     load_video,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PILImageResampling\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/transformers/image_utils.py:65\u001b[39m\n\u001b[32m     62\u001b[39m     PILImageResampling = PIL.Image\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io \u001b[38;5;28;01mas\u001b[39;00m torchvision_io\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[32m     68\u001b[39m     pil_torch_interpolation_mapping = {\n\u001b[32m     69\u001b[39m         PILImageResampling.NEAREST: InterpolationMode.NEAREST,\n\u001b[32m     70\u001b[39m         PILImageResampling.BOX: InterpolationMode.BOX,\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m         PILImageResampling.LANCZOS: InterpolationMode.LANCZOS,\n\u001b[32m     75\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torchvision/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torchvision/models/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malexnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvnext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdensenet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mefficientnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torchvision/models/convnext.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstochastic_depth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_presets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torchvision/ops/__init__.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgiou_loss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoolers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mps_roi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mps_roi_pool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torchvision/ops/poolers.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mroi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;129m@torch\u001b[39m.jit.unused\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) -> Tensor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mannotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torch/_dynamo/distributed.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdist\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m      8\u001b[39m _COMPILE_PG: Optional[dist.ProcessGroup] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_compile_pg\u001b[39m() -> Optional[dist.ProcessGroup]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:551\u001b[39m\n\u001b[32m    547\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_closure_patcher\u001b[39m(**changes):\n\u001b[32m    548\u001b[39m         ...\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m \u001b[43minstall_config_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torch/utils/_config_module.py:151\u001b[39m, in \u001b[36minstall_config_module\u001b[39m\u001b[34m(module)\u001b[39m\n\u001b[32m    147\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnhandled config \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m config: Dict[\u001b[38;5;28mstr\u001b[39m, _ConfigEntry] = {}\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m compile_ignored_keys = \u001b[43mget_assignments_with_compile_ignored_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m visit(module, module, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m module._config = config  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/torch/utils/_config_module.py:187\u001b[39m, in \u001b[36mget_assignments_with_compile_ignored_comments\u001b[39m\u001b[34m(module)\u001b[39m\n\u001b[32m    183\u001b[39m         current_comment = maybe_current, token.start[\u001b[32m0\u001b[39m]\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m token.type == tokenize.NAME:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# Only accept the first name token, to handle if you have\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# something like foo: Bar = ...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prev_name:\n\u001b[32m    188\u001b[39m         prev_name = token.string\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m token.type == tokenize.OP \u001b[38;5;129;01mand\u001b[39;00m token.string == \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# Check if the current assignment follows a comment\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;66;03m# with COMPILE_IGNORED_MARKER\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "from vllm.engine.async_llm_engine import AsyncLLMEngine\n",
    "from vllm.engine.arg_utils import AsyncEngineArgs\n",
    "\n",
    "engine = AsyncLLMEngine.from_engine_args(\n",
    "    AsyncEngineArgs(\n",
    "        **{\n",
    "            \"model\": \"unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit\",\n",
    "            \"gpu_memory_utilization\": 0.545824483248941,\n",
    "            \"max_model_len\": 32768,\n",
    "            \"quantization\": \"bitsandbytes\",\n",
    "            \"load_format\": \"bitsandbytes\",\n",
    "            \"kv_cache_dtype\": \"auto\",\n",
    "            \"max_num_batched_tokens\": 32768,\n",
    "            \"max_num_seqs\": 320,\n",
    "            \"max_logprobs\": 0,\n",
    "            \"seed\": 0,\n",
    "            \"enable_lora\": True,\n",
    "            \"max_lora_rank\": 8,\n",
    "            \"max_loras\": 1,\n",
    "            \"disable_log_stats\": False,\n",
    "            \"enable_prefix_caching\": True,\n",
    "            \"max_seq_len_to_capture\": 8192,\n",
    "            \"compilation_config\": 3,\n",
    "            \"enforce_eager\": False,\n",
    "            \"swap_space\": 6,\n",
    "            \"device\": \"cuda:0\",\n",
    "            \"num_scheduler_steps\": 16,\n",
    "            \"enable_sleep_mode\": True,\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-03 02:53:27 [worker.py:133] Sleep mode freed 39.50 GiB memory, 5.10 GiB memory is still in use.\n",
      "INFO 04-03 02:53:27 [executor_base.py:208] It took 0.316336 seconds to fall asleep.\n"
     ]
    }
   ],
   "source": [
    "await engine.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-03 03:44:10 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcpuser/sky_workdir/src/art/unsloth/state.py:2: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  import unsloth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.18: Fast Qwen2 patching. Transformers: 4.49.0. vLLM: 0.8.2.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit with actual GPU utilization = 54.58%\n",
      "Unsloth: Your GPU has CUDA compute capability 9.0 with VRAM = 79.11 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 32768. Num Sequences = 320.\n",
      "Unsloth: vLLM's KV Cache can use up to 37.31 GB. Also swap space = 6 GB.\n",
      "INFO 04-03 03:44:21 [config.py:585] This model supports multiple tasks: {'score', 'reward', 'classify', 'generate', 'embed'}. Defaulting to 'generate'.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.0.self_attn', 'model.layers.1.self_attn', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.4.mlp', 'model.layers.25.mlp', 'model.layers.26.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 04-03 03:44:21 [llm_engine.py:241] Initializing a V0 LLM engine (v0.8.2) with config: model='unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit, num_scheduler_steps=16, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":320}, use_cached_outputs=False, \n",
      "INFO 04-03 03:44:22 [cuda.py:291] Using Flash Attention backend.\n",
      "WARNING 04-03 03:44:22 [registry.py:337] `mm_limits` has already been set for model=unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit, and will be overwritten by the new values.\n",
      "INFO 04-03 03:44:22 [parallel_state.py:954] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-03 03:44:22 [model_runner.py:1110] Starting to load model unsloth/qwen2.5-7b-instruct-unsloth-bnb-4bit...\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "INFO 04-03 03:44:22 [loader.py:1155] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 04-03 03:44:23 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f23381e8fdb4175a2c85f439e44bba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a339325f6248d0992ab98b2743c2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-03 03:44:25 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "INFO 04-03 03:44:26 [model_runner.py:1146] Model loading took 6.7357 GB and 3.243111 seconds\n",
      "INFO 04-03 03:44:28 [worker.py:267] Memory profiling takes 2.31 seconds\n",
      "INFO 04-03 03:44:28 [worker.py:267] the current vLLM instance can use total_gpu_memory (79.11GiB) x gpu_memory_utilization (0.55) = 43.18GiB\n",
      "INFO 04-03 03:44:28 [worker.py:267] model weights take 6.74GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 4.72GiB; the rest of the memory reserved for KV Cache is 31.57GiB.\n",
      "INFO 04-03 03:44:29 [executor_base.py:111] # cuda blocks: 36946, # CPU blocks: 7021\n",
      "INFO 04-03 03:44:29 [executor_base.py:116] Maximum concurrency for 32768 tokens per request: 18.04x\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "python_malloc_callback\n",
      "INFO 04-03 03:44:31 [model_runner.py:1442] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 43/43 [00:30<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-03 03:45:01 [model_runner.py:1570] Graph capturing finished in 30 secs, took 4.29 GiB\n",
      "INFO 04-03 03:45:01 [llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 35.41 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth 2025.3.18 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# import unsloth\n",
    "import os\n",
    "from art.config.model import get_model_config, ModelConfig\n",
    "from art.unsloth.state import ModelState\n",
    "\n",
    "os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"\"\n",
    "config = get_model_config(\n",
    "    \"Qwen/Qwen2.5-7B-Instruct\", output_dir=\"./.art/models/test\", config={\"init_args\": {\"load_in_4bit\": True}}\n",
    ")\n",
    "state = ModelState(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-03 03:45:27 [worker.py:133] Sleep mode freed 39.47 GiB memory, 5.23 GiB memory is still in use.\n",
      "INFO 04-03 03:45:27 [executor_base.py:208] It took 5.406892 seconds to fall asleep.\n"
     ]
    }
   ],
   "source": [
    "await state.vllm.async_engine.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Sleep mode is not enabled in the model config",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m state.vllm.async_engine.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/engine/async_llm_engine.py:1223\u001b[39m, in \u001b[36mAsyncLLMEngine.sleep\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(\u001b[38;5;28mself\u001b[39m, level: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1223\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/vllm/engine/llm_engine.py:1941\u001b[39m, in \u001b[36mLLMEngine.sleep\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   1940\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(\u001b[38;5;28mself\u001b[39m, level: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1941\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vllm_config.model_config.enable_sleep_mode, (\n\u001b[32m   1942\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSleep mode is not enabled in the model config\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1943\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_executor.sleep(level=level)\n",
      "\u001b[31mAssertionError\u001b[39m: Sleep mode is not enabled in the model config"
     ]
    }
   ],
   "source": [
    "await state.vllm.async_engine.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for xs in state.vllm.driver_worker.gpu_cache:\n",
    "    for x in xs:\n",
    "        # x.data = x.data.to(\"cpu\", non_blocking=True)\n",
    "        print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33114368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x.element_size() * x.nelement() for xs in state.vllm.driver_worker.gpu_cache for x in xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 100,000 | Num Epochs = 3 | Total steps = 300,000\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 20,185,088/7,635,801,600 (0.26% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from art.unsloth.train import train\n",
    "\n",
    "train_task = asyncio.create_task(train(state.trainer, asyncio.Queue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.types import TuneConfig\n",
    "from art.unsloth.service import TuneInputs\n",
    "import torch\n",
    "\n",
    "shape = (1, 32768)\n",
    "\n",
    "state.inputs_queue.put_nowait(\n",
    "    TuneInputs(\n",
    "        tokens=torch.randint(0, 100, shape),\n",
    "        group_ids=torch.randint(0, 10, shape),\n",
    "        parent_ids=torch.randint(0, 10, shape),\n",
    "        input_pos=torch.tensor([list(range(shape[1]))]),\n",
    "        assistant_mask=torch.ones(shape, dtype=torch.bool),\n",
    "        logprobs=torch.zeros(shape),\n",
    "        advantages=torch.zeros(shape),\n",
    "        weights=torch.ones(shape),\n",
    "        config=TuneConfig(lr=0.0, kl_coef=0.0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.optimizer import AcceleratedOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.optimizer import AcceleratedOptimizer\n",
    "\n",
    "if isinstance(state.trainer.optimizer, AcceleratedOptimizer):\n",
    "    import torch\n",
    "\n",
    "    def move_tensors(obj, to):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.to(to)\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: move_tensors(value, to) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [move_tensors(item, to) for item in obj]\n",
    "        elif isinstance(obj, tuple):\n",
    "            return tuple(move_tensors(item, to) for item in obj)\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    state.trainer.optimizer.optimizer.state_dict()[\"state\"] = move_tensors(\n",
    "        state.trainer.optimizer.optimizer.state_dict()[\"state\"], torch.device(\"cuda:0\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total optimizer memory: 0.0389 GiB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def calculate_memory(obj):\n",
    "    total = 0\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        # Multiply element size (in bytes) by number of elements.\n",
    "        total += obj.element_size() * obj.nelement()\n",
    "    elif isinstance(obj, dict):\n",
    "        for value in obj.values():\n",
    "            total += calculate_memory(value)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            total += calculate_memory(item)\n",
    "    return total\n",
    "\n",
    "\n",
    "# Get the optimizer's state dictionary, which typically contains the tensors\n",
    "optimizer_state = state.trainer.optimizer.optimizer.state_dict().get(\"state\", {})\n",
    "total_bytes = calculate_memory(optimizer_state)\n",
    "total_gib = total_bytes / (1024**3)\n",
    "\n",
    "print(f\"Total optimizer memory: {total_gib:.4f} GiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.vllm.driver_worker.vllm_config.model_config.enable_sleep_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vllm.device_allocator.cumem import CuMemAllocator\n",
    "\n",
    "CuMemAllocator.get_instance().pointer_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.unsloth.train import free_memory\n",
    "\n",
    "free_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weight_decay': 0.1,\n",
       "  'lr': 5e-06,\n",
       "  'betas': (0.9, 0.99),\n",
       "  'eps': 1e-08,\n",
       "  'alpha': 0.0,\n",
       "  't_alpha': None,\n",
       "  't_beta3': None,\n",
       "  'initial_lr': 5e-06,\n",
       "  'params': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   241,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   245,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   260,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   264,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   274,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   278,\n",
       "   279,\n",
       "   280,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   289,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   300,\n",
       "   301,\n",
       "   302,\n",
       "   303,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   310,\n",
       "   311,\n",
       "   312,\n",
       "   313,\n",
       "   314,\n",
       "   315,\n",
       "   316,\n",
       "   317,\n",
       "   318,\n",
       "   319,\n",
       "   320,\n",
       "   321,\n",
       "   322,\n",
       "   323,\n",
       "   324,\n",
       "   325,\n",
       "   326,\n",
       "   327,\n",
       "   328,\n",
       "   329,\n",
       "   330,\n",
       "   331,\n",
       "   332,\n",
       "   333,\n",
       "   334,\n",
       "   335,\n",
       "   336,\n",
       "   337,\n",
       "   338,\n",
       "   339,\n",
       "   340,\n",
       "   341,\n",
       "   342,\n",
       "   343,\n",
       "   344,\n",
       "   345,\n",
       "   346,\n",
       "   347,\n",
       "   348,\n",
       "   349,\n",
       "   350,\n",
       "   351,\n",
       "   352,\n",
       "   353,\n",
       "   354,\n",
       "   355,\n",
       "   356,\n",
       "   357,\n",
       "   358,\n",
       "   359,\n",
       "   360,\n",
       "   361,\n",
       "   362,\n",
       "   363,\n",
       "   364,\n",
       "   365,\n",
       "   366,\n",
       "   367,\n",
       "   368,\n",
       "   369,\n",
       "   370,\n",
       "   371,\n",
       "   372,\n",
       "   373,\n",
       "   374,\n",
       "   375,\n",
       "   376,\n",
       "   377,\n",
       "   378,\n",
       "   379,\n",
       "   380,\n",
       "   381,\n",
       "   382,\n",
       "   383,\n",
       "   384,\n",
       "   385,\n",
       "   386,\n",
       "   387,\n",
       "   388,\n",
       "   389,\n",
       "   390,\n",
       "   391]},\n",
       " {'weight_decay': 0.0,\n",
       "  'lr': 5e-06,\n",
       "  'betas': (0.9, 0.99),\n",
       "  'eps': 1e-08,\n",
       "  'alpha': 0.0,\n",
       "  't_alpha': None,\n",
       "  't_beta3': None,\n",
       "  'initial_lr': 5e-06,\n",
       "  'params': []}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.trainer.optimizer.optimizer.state_dict()[\"param_groups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidStateError",
     "evalue": "Result is not ready.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidStateError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_task\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidStateError\u001b[39m: Result is not ready."
     ]
    }
   ],
   "source": [
    "train_task.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
