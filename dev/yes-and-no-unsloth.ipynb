{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Started service on localhost:8089 (PID: 16907)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbc2b3c57784bcd8c60abbd4e48e9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/1152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbradhilton\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gcpuser/sky_workdir/dev/wandb/run-20250328_014441-yes-or-no-unsloth-001</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/bradhilton/agent-reinforcement-training/runs/yes-or-no-unsloth-001' target=\"_blank\">yes-or-no-unsloth-001</a></strong> to <a href='https://wandb.ai/bradhilton/agent-reinforcement-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bradhilton/agent-reinforcement-training' target=\"_blank\">https://wandb.ai/bradhilton/agent-reinforcement-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bradhilton/agent-reinforcement-training/runs/yes-or-no-unsloth-001' target=\"_blank\">https://wandb.ai/bradhilton/agent-reinforcement-training/runs/yes-or-no-unsloth-001</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared tuning data with 2 sequences of length 8192\n"
     ]
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Client error '422 Unprocessable Entity' for url 'http://localhost:8089/tune'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m model.get_iteration(), \u001b[32m1_000\u001b[39m):\n\u001b[32m     43\u001b[39m     train_groups = \u001b[38;5;28;01mawait\u001b[39;00m art.gather_trajectories(\n\u001b[32m     44\u001b[39m         (\n\u001b[32m     45\u001b[39m             (rollout(openai_client, prompt) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m32\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m         stream_chat_completions=\u001b[32m8\u001b[39m,\n\u001b[32m     65\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m model.tune(\n\u001b[32m     67\u001b[39m         train_groups,\n\u001b[32m     68\u001b[39m         config=art.TuneConfig(\n\u001b[32m     69\u001b[39m             sequence_length=\u001b[32m8192\u001b[39m, plot_tensors=\u001b[38;5;28;01mFalse\u001b[39;00m, verbosity=\u001b[32m2\u001b[39m\n\u001b[32m     70\u001b[39m         ),\n\u001b[32m     71\u001b[39m     )\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/model.py:104\u001b[39m, in \u001b[36mModel.tune\u001b[39m\u001b[34m(self, trajectory_groups, config)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtune\u001b[39m(\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     93\u001b[39m     trajectory_groups: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Trajectory | \u001b[38;5;167;01mBaseException\u001b[39;00m]],\n\u001b[32m     94\u001b[39m     config: TuneConfig = TuneConfig(),\n\u001b[32m     95\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[33;03m    Reinforce fine-tune the model with a batch of trajectory groups.\u001b[39;00m\n\u001b[32m     98\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m            loss, other hyperparameters, logging, etc.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api._tune_model(\u001b[38;5;28mself\u001b[39m, trajectory_groups, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/unsloth/api.py:298\u001b[39m, in \u001b[36mUnslothAPI._tune_model\u001b[39m\u001b[34m(self, model, trajectory_groups, config)\u001b[39m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    295\u001b[39m disk_packed_tensors = packed_tensors_to_dir(\n\u001b[32m    296\u001b[39m     packed_tensors, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._get_output_dir(model.name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    297\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m service.tune(disk_packed_tensors, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/src/art/model_service/__init__.py:195\u001b[39m, in \u001b[36mModelService.serve.<locals>.tune\u001b[39m\u001b[34m(disk_packed_tensors, config)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtune\u001b[39m(\n\u001b[32m    185\u001b[39m     disk_packed_tensors: \u001b[33m\"\u001b[39m\u001b[33mDiskPackedTensors\u001b[39m\u001b[33m\"\u001b[39m, config: types.TuneConfig\n\u001b[32m    186\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    187\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m client.post(\n\u001b[32m    188\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/tune\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    189\u001b[39m         json={\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m         timeout=httpx.Timeout(\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    194\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sky_workdir/.venv/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    827\u001b[39m error_type = error_types.get(status_class, \u001b[33m\"\u001b[39m\u001b[33mInvalid status code\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '422 Unprocessable Entity' for url 'http://localhost:8089/tune'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/422"
     ]
    }
   ],
   "source": [
    "import art\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api = art.UnslothAPI(wandb_project=\"agent-reinforcement-training\")\n",
    "model = await api.get_or_create_model(\n",
    "    name=\"yes-or-no-unsloth-001\",\n",
    "    base_model=\"unsloth/Qwen2.5-14B-Instruct\",\n",
    ")\n",
    "\n",
    "\n",
    "async def rollout(client: openai.AsyncOpenAI, prompt: str) -> art.Trajectory:\n",
    "    messages: art.Messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ]\n",
    "    chat_completion = await client.chat.completions.create(\n",
    "        messages=messages, model=model.name, max_tokens=100\n",
    "    )\n",
    "    choice = chat_completion.choices[0]\n",
    "    content = choice.message.content\n",
    "    assert isinstance(content, str)\n",
    "    if content == \"yes\":\n",
    "        reward = 0.5\n",
    "    elif content == \"no\":\n",
    "        reward = 0.75\n",
    "    elif content == \"maybe\":\n",
    "        reward = 1.0\n",
    "    else:\n",
    "        reward = 0.0\n",
    "    return art.Trajectory(messages_and_choices=[*messages, choice], reward=reward)\n",
    "\n",
    "\n",
    "async with model.openai_client(\n",
    "    estimated_completion_tokens=16, verbosity=2\n",
    ") as openai_client:\n",
    "    for i in range(await model.get_iteration(), 1_000):\n",
    "        train_groups = await art.gather_trajectories(\n",
    "            (\n",
    "                (rollout(openai_client, prompt) for _ in range(32))\n",
    "                for prompt in [\n",
    "                    f\"{prefix} with {', '.join([f\"'{w}'\" if use_quotes else w for w in words]) if len(words) == 3 else f'{words[0]}' + (f' or {words[1]}' if len(words) > 1 else '')}\"\n",
    "                    for prefix in [\"respond\", \"just respond\"]\n",
    "                    for use_quotes in [True, False]\n",
    "                    for words in [\n",
    "                        [\"yes\", \"no\", \"maybe\"],\n",
    "                        [\"maybe\", \"yes\", \"no\"],\n",
    "                        [\"no\", \"yes\", \"maybe\"],\n",
    "                        [\"yes\", \"maybe\", \"no\"],\n",
    "                        [\"yes\", \"no\"],\n",
    "                        [\"maybe\", \"no\"],\n",
    "                        [\"no\", \"maybe\"],\n",
    "                        [\"no\", \"yes\"],\n",
    "                        [\"yes\", \"no\"],\n",
    "                    ]\n",
    "                ]\n",
    "            ),\n",
    "            pbar_desc=\"train\",\n",
    "            stream_chat_completions=8,\n",
    "        )\n",
    "        await model.tune(\n",
    "            train_groups,\n",
    "            config=art.TuneConfig(\n",
    "                sequence_length=8192, plot_tensors=False, verbosity=2\n",
    "            ),\n",
    "        )\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
